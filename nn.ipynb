{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `nn.ipynb`\n",
    "This file aims to use a neural network to solve the multiple-peaks problem. There is information in the peaks and positions of the nodes, but we haven't been able to draw it out yet. Maybe a neural network can."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN specs\n",
    "* Input\n",
    "    * Positions of N nodes\n",
    "    * Peaks of N-1 MIs, the peak closest to zero\n",
    "    * Period: avg period of each signal using MI between signal and self\n",
    "    * Total: 3N inputs\n",
    "* Output\n",
    "    * N-1 peaks/time delays\n",
    "\n",
    "More details below..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Liberties (assumptions) taken:\n",
    "* When finding the period, you need an upper bound. This could be deduced using the speed and the width of the space, but I am just using a fraction of the signal length. I happen to know that one fifth of the length of the signal (`2000 // 5 = 400`, or `1600 // 6 = 320`) always contains the period. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other notes:\n",
    "* This is the first time I am implementing a randomization of the target location in FN data, of a sort. There will be a bounding box with a minimum size of 50 in each direction, where all the target nodes have to live inside. This way, we do not need to regenerate the FN data each time, but the target is still at a random position relative to the nodes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from WSN import *\n",
    "import mutual_information as mtin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtin.default_fn_equ_params[\"dt\"] = 0.01\n",
    "mtin.default_fn_equ_params[\"T\"] = 20_000\n",
    "mtin.default_fn_equ_params['stim'] = [[[250, 350], [45, 65], [45, 65]]]\n",
    "start_frame = int(40 / mtin.default_fn_equ_params[\"dt\"])\n",
    "mtin.default_fn_equ = FHN(**mtin.default_fn_equ_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mtin.default_fn_sol is None:\n",
    "    mtin.default_fn_sol = np.load(\"default_fn_sol_dt_0.01.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mtin.solve_default_fn_equ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(\"default_fn_sol_dt_0.01.npy\", mtin.default_fn_sol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate signals and find all peaks\n",
    "def get_fn_peaks_inside_period(self: WSN, r0=None, use_mst=False):\n",
    "    if r0 is None:\n",
    "        r0 = np.array([55, 55])\n",
    "    results = self.transmit_continuous(signal_type=\"fn\", start_frame=start_frame)\n",
    "    assert np.all(np.array([result[0] for result in results]) == self.nodes)\n",
    "\n",
    "    self.printv(\"Finding period\")\n",
    "    avg_period = 0\n",
    "    for i, sigi in results:\n",
    "        # This is arbitrary, but I know this will work for this case\n",
    "        max_tau = len(sigi) // 5\n",
    "        shifts = np.arange(-max_tau, max_tau, 1)\n",
    "        mis = mi_shift(np.transpose([sigi, sigi]), shifts)\n",
    "\n",
    "        mis = np.array(mis)\n",
    "        max_peak = mis.max()\n",
    "        peaks, _ = find_peaks(mis)\n",
    "        peaks = peaks[np.argsort(mis[peaks])]\n",
    "        peaks = peaks[-5:]\n",
    "        peaks.sort()\n",
    "        period1 = peaks[1] - peaks[0]\n",
    "        period2 = peaks[2] - peaks[1]\n",
    "        period = (period1 + period2) / 2\n",
    "        dt = mtin.default_fn_equ_params[\"dt\"]\n",
    "        period *= dt\n",
    "        avg_period += period\n",
    "    avg_period /= len(results)\n",
    "    self.printv(\"Period found to be\", avg_period)\n",
    "\n",
    "    all_peaks = []   # [(rn, rm, p, p0), ...]\n",
    "    pair_to_ind = {} # {(n, m): i}\n",
    "\n",
    "    # For now, tree must be a list so that the neural network\n",
    "    # sees the peaks in the same order every time\n",
    "    if use_mst:\n",
    "        tree = list(self.find_MST())\n",
    "    else:\n",
    "        tree = [\n",
    "            (None, 0, i)\n",
    "            for i in range(1, len(self.nodes))\n",
    "        ]\n",
    "    for _, i, j in tree:\n",
    "        ri, sigi = results[i]\n",
    "        rj, sigj = results[j]\n",
    "        dt = mtin.default_fn_equ_params[\"dt\"]\n",
    "        max_tau = int((2 * avg_period) / dt)\n",
    "        shifts = np.arange(-max_tau, max_tau, 1)\n",
    "        mis = mtin.mi_shift(np.transpose([sigi, sigj]), shifts)\n",
    "\n",
    "        mis = np.array(mis)\n",
    "        max_peak = mis.max()\n",
    "        inclusion_factor = 0.5\n",
    "        peaks, _ = find_peaks(mis, height=max_peak * inclusion_factor)\n",
    "        if self.verbose and np.random.uniform(0, 1) < 0.1:\n",
    "            plt.plot(shifts, mis)\n",
    "            plt.show(block=False)\n",
    "        if len(peaks) == 0:\n",
    "            plt.plot(shifts * mtin.default_fn_equ_params[\"dt\"], mis)\n",
    "            plt.show(block=False)\n",
    "            p = (dist(ri, r0) - dist(rj, r0)) / self.c\n",
    "            raise ValueError(\n",
    "                f\"No peaks found between nodes {i} and {j} \"\n",
    "                f\"at positions {ri} and {rj}.\\n\"\n",
    "                f\"The peak should be at time {p}.\"\n",
    "            )\n",
    "        peaks = shifts[peaks]\n",
    "        # p0 = peak closest to 0\n",
    "        p0 = peaks[np.argmin(np.abs(peaks))]\n",
    "\n",
    "        # p = ideal peak\n",
    "        p = (dist(ri, r0) - dist(rj, r0)) / self.c\n",
    "        pair_to_ind[(i, j)] = len(all_peaks)\n",
    "        all_peaks.append((ri, rj, p, p0))\n",
    "    return all_peaks, pair_to_ind, avg_period\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[setattr(WSN, attr, globals()[attr]) for attr in (\n",
    "    \"get_fn_peaks_inside_period\",\n",
    ")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create testing and training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input format:\n",
    "* `x0, y0, x1, y1, ...`   (normalized by `wsn.size`)\n",
    "* `p0, p1, p2, ...`       (normalized by period)\n",
    "* `period`\n",
    "\n",
    "Output format:\n",
    "* `p0, p1, p2, ...`       (normalized by period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 12\n",
    "c = 1.6424885622140555\n",
    "wsn = WSN(100, N, D=142, std=0, c=c, verbose=False)\n",
    "wsn.reset_anchors(range(N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_and_output(wsn: WSN):\n",
    "    all_peaks, pair_to_ind, period = wsn.get_fn_peaks_inside_period()\n",
    "    # Input format:\n",
    "    # [\n",
    "    #   wsn.nodes.flatten() -- len = 2N,\n",
    "    #   peaks -- len = N-1,\n",
    "    #   period -- len = 1\n",
    "    # ]\n",
    "\n",
    "    # Output format:\n",
    "    # peaks -- len = N-1\n",
    "    input = []\n",
    "    output = []\n",
    "    for ri, rj, p, p0 in all_peaks:\n",
    "        input.append(p0 / period)\n",
    "        output.append(p / period)\n",
    "    input.append(period)\n",
    "    input = np.concatenate((wsn.nodes.flatten() / 100, input))\n",
    "    output = np.array(output)\n",
    "\n",
    "    return input, output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]d:\\Repositories\\WSN-Localization\\mutual_information.py:105: RuntimeWarning: divide by zero encountered in log\n",
      "  mi = -0.5 * np.log(np.linalg.det(cor))\n",
      "100%|██████████| 100/100 [46:51<00:00, 28.12s/it]\n"
     ]
    }
   ],
   "source": [
    "data_size = 100\n",
    "# input_shape = (data_size, 3 * N)\n",
    "# output_shape = (data_size, N - 1)\n",
    "input = [0] * data_size\n",
    "output = [0] * data_size\n",
    "for j in tqdm(range(data_size)):\n",
    "    error = True\n",
    "    while error:\n",
    "        error = False\n",
    "        try:\n",
    "            wsn.reset_nodes()\n",
    "            i, o = get_input_and_output(wsn)\n",
    "            input[j] = i\n",
    "            output[j] = o\n",
    "        except ValueError as e:\n",
    "            print(f\"ValueError: {e}\")\n",
    "            error = True\n",
    "input = np.array(input)\n",
    "output = np.array(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"nn_saves/input.npy\", input)\n",
    "np.save(\"nn_saves/output.npy\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_samples = data_size * 8 // 10\n",
    "train_input = input[:num_train_samples]\n",
    "train_output = output[:num_train_samples]\n",
    "test_input = input[num_train_samples:]\n",
    "test_output = output[num_train_samples:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(3*N,)),\n",
    "    keras.layers.Dense(128, activation=\"relu\"),\n",
    "    keras.layers.Dense(128, activation=\"relu\"),\n",
    "    keras.layers.Dense(128, activation=\"relu\"),\n",
    "    keras.layers.Dense(128, activation=\"relu\"),\n",
    "    keras.layers.Dense(128, activation=\"relu\"),\n",
    "    keras.layers.Dense(128, activation=\"relu\"),\n",
    "    keras.layers.Dense(N-1, activation=\"linear\")\n",
    "])\n",
    "model.compile(optimizer=\"adam\", loss=\"mean_squared_error\", metrics=[\"mean_squared_error\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"d:\\Repositories\\WSN-Localization\\vwsn\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"d:\\Repositories\\WSN-Localization\\vwsn\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"d:\\Repositories\\WSN-Localization\\vwsn\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"d:\\Repositories\\WSN-Localization\\vwsn\\lib\\site-packages\\keras\\engine\\training.py\", line 889, in train_step\n        y_pred = self(x, training=True)\n    File \"d:\\Repositories\\WSN-Localization\\vwsn\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"d:\\Repositories\\WSN-Localization\\vwsn\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 36), found shape=(None, 37)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\Repositories\\WSN-Localization\\nn.ipynb Cell 20\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Repositories/WSN-Localization/nn.ipynb#ch0000026?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(train_input, train_output, epochs\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m)\n",
      "File \u001b[1;32md:\\Repositories\\WSN-Localization\\vwsn\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileadgfo8p4.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"d:\\Repositories\\WSN-Localization\\vwsn\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"d:\\Repositories\\WSN-Localization\\vwsn\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"d:\\Repositories\\WSN-Localization\\vwsn\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"d:\\Repositories\\WSN-Localization\\vwsn\\lib\\site-packages\\keras\\engine\\training.py\", line 889, in train_step\n        y_pred = self(x, training=True)\n    File \"d:\\Repositories\\WSN-Localization\\vwsn\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"d:\\Repositories\\WSN-Localization\\vwsn\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 36), found shape=(None, 37)\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_input, train_output, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_mse = model.evaluate(test_input, test_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('vwsn': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0a326387514bff8cff46362682c6b5d6706650c507f9d6555fe15603d3afa14e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
